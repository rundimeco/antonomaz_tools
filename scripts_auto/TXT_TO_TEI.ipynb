{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TXT_to_XML-TEI personnalisé avec métadonnées pré-remplies\n",
    "* En entrée : fichier .txt concaténé et pré-encodé de l'océrisation\n",
    "* En sortie : un fichier xml avec TEI header pré-rempli (dont métadonnées du texte : titre, date de publi, lieu de publi, geonames, url du pdf, url de la notice BM, vers/prose...)\n",
    "* Données nécessaires : tableurs Avancée_travail_corpus et ListeMazarinades en tsv (séparateur : tabulation)\n",
    "* Le mode d'emploi du script se trouve dans le dernière cellule (\"Exemple d'utilisation\").\n",
    "\n",
    "/ ! \\ l'encodage automatique des fichiers se fait par alignement du nom du fichier avec l'id équivalent dans les tableurs. De fait, ce script ne fonctionne pas sur des fichiers dont le nom n'est pas strictement l'id Moreau,Labadie ou Socard (ex : Moreau85-2_GBOOKS ne marchera pas. En revanche, Moreau85_GBOOKS est ok.)\n",
    "\n",
    "/ ! \\ Ce script suit des process différents selon que les fichiers à encoder proviennent de GBOOKS, Gallica ou la BM. Chaque session d'encodage auto doit donc se faire sur des fichiers provenant de la même source. Cette source est à préciser en paramètre de la fonction XML_generate()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import des librairies nécessaires\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XML_generate(fichier_corpus=\"non_classé\",genre=\"non renseigné\",date_creation_fichier=\"3 juin 2021\",\n",
    "                 when_creation_fichier=\"2021-06-03\",name_respXML=\"Roblin Camille\",status_respXML=\"Stagiaire\",\n",
    "                 path_avancee_corpus=\"Avancée_travail_corpus - Corpus_complet.tsv\", \n",
    "                 path_ListeMaz=\"ListeMazarinades - Documents_all.tsv\", source_doc=\"GALL\"):\n",
    "                #Pour créer la structure XML-TEI + pré-remplir certains champs \n",
    "                #fichier_corpus : Ecrire le corpus dont font partie les documents (mazarinades_lettres, mazarinades_narration, \n",
    "                #mazarinades_chantables, sans indication). Il ne doit pas y avoir d'espace.\n",
    "                #genre : genre du texte qui apparaitra dans les mots clés (lettre, chantable...)\n",
    "                #date_creation_fichier : Ecrire  la date de lancement du script selon le format \"3 juin 2021\"\n",
    "                #when_creation_fichier : Ecrire  la date de lancement du script selon le format \"2021-06-03\"\n",
    "                #name_respXML et status_respXML : nom, prénom et statut de la personne responsable de la chaine de traitement TXT>XML\n",
    "                #path_avancee_corpus : path vers la feuille du tableur Avancée_travail_corpus\n",
    "                #path_ListeMaz : path vers la feuille du tableur ListeMazarinades\n",
    "                #Source_doc : source des fichiers originaux (\"GALL\", \"GBOOKS\" ou \"MAZ\")\n",
    "    \n",
    "#Création de la structure XML-TEI générale\n",
    "    \n",
    "    #Création de l'élément racine, en l'occurence \"TEI\"\n",
    "    root=ET.Element('TEI')\n",
    "    root.set('xmlns','http://www.tei-c.org/ns/1.0')\n",
    "    root.set('type',fichier_corpus)\n",
    "    #Création du TEI Header\n",
    "    teiHeader=ET.SubElement(root,'teiHeader')\n",
    "    #Création du contenu de fileDesc\n",
    "    fileDesc=ET.SubElement(teiHeader,'fileDesc') #Dès qu'on crée un sous-élément\n",
    "    titleStmt=ET.SubElement(fileDesc,'titleStmt')\n",
    "    title1=ET.SubElement(titleStmt,'title')\n",
    "    title2=ET.SubElement(titleStmt,'title')\n",
    "    title1.set('type','main') #On ajoute les attributs des balises\n",
    "    title1.set('source','Moreau')\n",
    "    title2.set('type','sub')\n",
    "    title2.text=\"ANTONOMAZ édition\" #On remplit la balise\n",
    "    #Contenu de respStmt\n",
    "    respStmt=ET.SubElement(titleStmt,'respStmt')\n",
    "    resp=ET.SubElement(respStmt,\"resp\")\n",
    "    resp.text=\"Chaîne de traitement\"\n",
    "    #Création et remplissage des balises pour responsable encodage XML-TEI\n",
    "    persName_equipe_1=ET.SubElement(respStmt,'persName')\n",
    "    persName_equipe_1.set('role','XML_Encoding')\n",
    "    persName_equipe_1.text= name_respXML\n",
    "    affiliation_equipe_1=ET.SubElement(persName_equipe_1,'affiliation')\n",
    "    roleName_equipe_1=ET.SubElement(affiliation_equipe_1,\"roleName\")\n",
    "    roleName_equipe_1.set('type','status')\n",
    "    roleName_equipe_1.text=status_respXML\n",
    "    #Création et remplissage des balises pour les chefs de projet\n",
    "    #Chef projet 1\n",
    "    persName_equipe_3=ET.SubElement(respStmt,'persName')\n",
    "    persName_equipe_3.set('role','Project_manager')\n",
    "    persName_equipe_3.set('ref','0000-0001-9518-1040')\n",
    "    persName_equipe_3.text=\"Abiven Karine\"\n",
    "    #Chef projet 2\n",
    "    persName_equipe_4=ET.SubElement(respStmt,'persName')\n",
    "    persName_equipe_4.set('role','Project_manager')\n",
    "    persName_equipe_4.set('ref','0000-0002-4795-2362')\n",
    "    persName_equipe_4.text=\"Lejeune Gaël\"\n",
    "    #Création et remplissage des balises pour la personne responsable de l'OCRisation\n",
    "    persName_equipe_5=ET.SubElement(respStmt,'persName')\n",
    "    persName_equipe_5.set('role','OCRisation')\n",
    "    persName_equipe_5.text=\"Tanguy Jean-Baptiste\"\n",
    "    persName_equipe_5.set('ref','0000-0002-0007-1664')\n",
    "    #Création du publicationStmt\n",
    "    publicationStmt=ET.SubElement(fileDesc,'publicationStmt')\n",
    "    publisher=ET.SubElement(publicationStmt,'publisher')\n",
    "    publisher.text=\"Projet ANTONOMAZ / Sorbonne Université\"\n",
    "    date_crea=ET.SubElement(publicationStmt,'date')\n",
    "    date_crea.set('type','file_creation')\n",
    "    date_crea.text=date_creation_fichier\n",
    "    date_crea.set('when',when_creation_fichier)\n",
    "    availability=ET.SubElement(publicationStmt,'availability')\n",
    "    availability.set('status','restricted')\n",
    "    availability.set('n','cc-by')\n",
    "    licence=ET.SubElement(availability,'licence')\n",
    "    licence.set('target','https://creativecommons.org/licenses/by/4.0')\n",
    "    #Création du sourceDesc\n",
    "    sourceDesc=ET.SubElement(fileDesc,'sourceDesc')\n",
    "    bibl=ET.SubElement(sourceDesc,'bibl')\n",
    "    ref=ET.SubElement(bibl,'ref')\n",
    "    author=ET.SubElement(bibl,'author')\n",
    "    persName_author=ET.SubElement(author,'persName')\n",
    "    forename_author=ET.SubElement(persName_author,'forename')\n",
    "    surname_author=ET.SubElement(persName_author,'surname')\n",
    "    title3=ET.SubElement(bibl,'title')\n",
    "    title3.set(\"source\",\"Moreau\")\n",
    "    pubPlace=ET.SubElement(bibl,'pubPlace')\n",
    "    pubPlace.set('ref','geonames:0000000')\n",
    "    pubPlace.set('source','Moreau')\n",
    "    publisher_imp=ET.SubElement(bibl,'publisher')\n",
    "    publisher_imp.set('ref','isni:0000000')\n",
    "    persName_pub=ET.SubElement(publisher_imp,'persName')\n",
    "    forename_pub=ET.SubElement(persName_pub, 'forename')\n",
    "    surname_pub=ET.SubElement(persName_pub,'surname')\n",
    "    date_pub=ET.SubElement(bibl,'date')\n",
    "    date_pub.set('source','Moreau')\n",
    "    extent=ET.SubElement(bibl,'extent')\n",
    "    measure=ET.SubElement(extent,'measure')\n",
    "    measure.set('unit','page')\n",
    "    note_format=ET.SubElement(bibl,'note')\n",
    "    note_format.set('type','format')\n",
    "    note_Moreau=ET.SubElement(bibl,'note')\n",
    "    note_Moreau.set('type','Moreau_identifier')\n",
    "    #note_Labadie=ET.SubElement(bibl,'note')\n",
    "    #note_Labadie.set('type','Labadie_identifier')\n",
    "    #note_Socard=ET.SubElement(bibl,'note')\n",
    "    #note_Socard.set('type','Socard_identifier')\n",
    "    note_BM=ET.SubElement(bibl,'note')\n",
    "    note_BM.set('type','BM_identifier')\n",
    "    note_BM.set('cert','low')\n",
    "    ref_BM=ET.SubElement(bibl,'ref')\n",
    "    ref_BM.set('type','BM_notice')\n",
    "    ref_BM.set('cert','low')\n",
    "    #Création du msDesc\n",
    "    msDesc=ET.SubElement(sourceDesc,'msDesc')\n",
    "    msIdentifier=ET.SubElement(msDesc,'msIdentifier')\n",
    "    settlement=ET.SubElement(msIdentifier,'settlement')\n",
    "    institution=ET.SubElement(msIdentifier,'institution')\n",
    "    repository=ET.SubElement(msIdentifier,'repository')\n",
    "    idno=ET.SubElement(msIdentifier,'idno')\n",
    "    idno.set('type','cote')\n",
    "    history=ET.SubElement(msDesc,'history')\n",
    "    provenance=ET.SubElement(history,'provenance')\n",
    "    stamp=ET.SubElement(provenance,'stamp')\n",
    "    stamp.text=\"True/False\"\n",
    "    #Création de l'encodingDesc\n",
    "    encodingDesc=ET.SubElement(teiHeader,'encodingDesc')\n",
    "    projectDesc=ET.SubElement(encodingDesc,'projectDesc')\n",
    "    p_proj_1=ET.SubElement(projectDesc,'p')\n",
    "    p_proj_1.text=\"Cette édition a été réalisée dans le cadre du projet ANTONOMAZ. Son objectif principal est de fournir un texte destiné à l'exploration avec des outils électroniques. De ce fait, ce n'est ni une édition philologique, ni une édition pédagogique ou de redécouverte d'un auteur oublié.\"\n",
    "    p_proj_2=ET.SubElement(projectDesc,'p')\n",
    "    p_proj_2.text='Les textes encodés dans le cadre du projet ANTONOMAZ sont issus de numérisations de bibliothèques numériques publiques et de Google livres.'\n",
    "    p_proj_3=ET.SubElement(projectDesc,'p')\n",
    "    p_proj_3.text=\"L'édition présentée ici est issue d'un processus d'OCRisation réalisé avec Kraken.\"\n",
    "    editorialDecl=ET.SubElement(encodingDesc,'editorialDecl')\n",
    "    p_editorialDecl=ET.SubElement(editorialDecl,'p')\n",
    "    #Création de du profileDesc\n",
    "    profileDesc=ET.SubElement(teiHeader,'profileDesc')\n",
    "    langUsage=ET.SubElement(profileDesc,'langUsage')\n",
    "    language=ET.SubElement(langUsage,'language')\n",
    "    language.set('ident','fr')\n",
    "    language.text='Document en français'\n",
    "    abstract=ET.SubElement(profileDesc,'abstract')\n",
    "    p_abs=ET.SubElement(abstract,'p')\n",
    "    p_abs.set(\"source\",\"BM_notes\")\n",
    "    textClass=ET.SubElement(profileDesc,'textClass')\n",
    "    keywords=ET.SubElement(textClass,'keywords')\n",
    "    term_for_1=ET.SubElement(keywords,'term')\n",
    "    term_for_1.set('type','form')\n",
    "    term_for_1.text=\"vers/prose\"\n",
    "    term_for_2=ET.SubElement(keywords,'term')\n",
    "    term_for_2.set('type','genre')\n",
    "    term_for_2.text=genre\n",
    "    term_for_3=ET.SubElement(keywords,'term')\n",
    "    term_for_3.set('type','subgenre')\n",
    "    term_for_4=ET.SubElement(keywords,'term')\n",
    "    term_for_4.set('type','subgenre')\n",
    "    term_for_5=ET.SubElement(keywords,'term')\n",
    "    term_for_5.set('type','subject')\n",
    "    #Création du corps du document : \"text\" et \"body\"\n",
    "    text=ET.SubElement(root,'text')\n",
    "    body=ET.SubElement(text,'body')\n",
    "    \n",
    "#Enregistrement du XML pour chacun des fichier .txt présent au même niveau que le script\n",
    "    try:\n",
    "        os.mkdir('sortie_xml')\n",
    "    except:\n",
    "        pass\n",
    "    for filepath in glob.iglob('*.txt'):\n",
    "        id_moreau=re.sub(\".txt\",\"\",filepath)\n",
    "        id_moreau=re.sub(\"_GALL|_GBOOKS|_MAZ\",\"\",id_moreau)\n",
    "        print(id_moreau)\n",
    "        #Ajout des métadonnées dans le TEI header à partir du Excel \"Documents_All\" exporté en TSV\n",
    "        df=pd.read_csv(path_ListeMaz, sep='\\t', header=0)\n",
    "        p=re.compile(id_moreau+\"$\")#le $ sert à ce qu'un Moreau120 ne matche pas aussi le Moreau1201, Moreau1202 etc.\n",
    "        for i in range(len(df)):\n",
    "            #alignement du fichier avec les métadonnées du tableur\n",
    "            m=p.match(str(df.loc[i,\"id\"]))\n",
    "            if m:\n",
    "                title1.text=str(df.loc[i,\"titre\"])\n",
    "                title3.text=str(df.loc[i,\"titre\"])\n",
    "                lieu_publi=str(df.loc[i,\"lieu\"])\n",
    "                #remplissage auto du geonames en fonction du nom de la ville dans le tableur\n",
    "                pubPlace.text=lieu_publi\n",
    "                villes={\"Paris\":'geonames:2988507',\n",
    "                        \"Bâle\":'geonames:2661604',\n",
    "                        \"Orléans\":'geonames:2989317',\n",
    "                        \"Bordeaux\":'geonames:6455058',\n",
    "                        \"Rotterdam\":'geonames:2747891',\n",
    "                        \"Sedan\":'geonames:2975349',\n",
    "                        \"Pontoise\":'geonames:2986140',\n",
    "                        \"Embrun\":'geonames:3020251',\n",
    "                        \"Saint-Germain-En-Laye\":'geonames:2979783',\n",
    "                        \"Amsterdam (Paris)\":'geonames:2988507',\n",
    "                        \"Bruxelles\":'geonames:2802247',\n",
    "                        \"Rouen\":'geonames:2982652',\n",
    "                        \"Cologne\":'geonames:2886242',\n",
    "                        \"Lyon\":'geonames:2996944',\n",
    "                        \"La Haye\":'geonames:2747373',\n",
    "                        \"Troyes\":'geonames:2971549',\n",
    "                        \"Torino\":'geonames:3165524'}\n",
    "                for cle, valeur in villes.items():\n",
    "                    if lieu_publi==cle:\n",
    "                        pubPlace.set('ref',valeur)\n",
    "                #Remplissage auto des autres métadonnées\n",
    "                date_pub.text=str(df.loc[i,\"date_imprimée\"])\n",
    "                date_pub.set('when',str(df.loc[i,\"date_imprimée\"]))\n",
    "                measure.set('quantity',str(df.loc[i,\"nb pages\"]))\n",
    "                #Remplissage du note type = id_moreau\n",
    "                idMoreau=str(df.loc[i,\"id\"])\n",
    "                p2=re.compile(\"Moreau\")\n",
    "                m2=p2.match(idMoreau)\n",
    "                #si le texte est identifié par Moreau\n",
    "                if m2:\n",
    "                    idMoreau_nb=re.sub(\"Moreau\",\"\",idMoreau)\n",
    "                    note_Moreau.text=idMoreau_nb\n",
    "                #si le texte a un autre identifiant (labadie, socard...)\n",
    "                else:\n",
    "                    note_Moreau.text=\"Sans ID Moreau\"\n",
    "                print(\"Remplissage auto des métadonnées à partir du tableur ListeMaz: OK.\")\n",
    "        #Ajout des métadonnées dans le TEI header à partir du Excel \"Avancee_corpus\" exporté en TSV\n",
    "        df=pd.read_csv(path_avancee_corpus, sep='\\t', header=0)\n",
    "        p=re.compile(id_moreau+\"$\")\n",
    "        for i in range(len(df)):\n",
    "            m=p.match(str(df.loc[i,\"id\"]))\n",
    "            if m:\n",
    "                if source_doc==\"GALL\":\n",
    "                    ref.set('target',str(df.loc[i,\"PDF_GALLICA\"]))\n",
    "                elif source_doc==\"GBOOKS\":\n",
    "                    ref.set('target',str(df.loc[i,\"PDF_GBOOKS\"]))\n",
    "                elif source_doc==\"MAZ\":\n",
    "                    ref.set('target',str(df.loc[i,\"PDF_MAZ\"]))\n",
    "                ref_BM.set('target',str(df.loc[i,\"Notice BM\"]))\n",
    "                vers_prose=str(df.loc[i,\"Vers / Prose (corpus)\"])\n",
    "                if vers_prose==\"V\":\n",
    "                    term_for_1.text=\"vers\" #Vers ou Prose\n",
    "                elif vers_prose==\"P\":\n",
    "                    term_for_1.text=\"prose\"\n",
    "                elif vers_prose==\"VP\":\n",
    "                    term_for_1.text=\"vers/prose\"\n",
    "                else:\n",
    "                    term_for_1.text=\"non renseigné\"             \n",
    "                print(\"Remplissage auto des métadonnées à partir du tableur Avancee_corpus : OK.\")\n",
    "        #Ajout du texte concaténé et encodé dans le body du XML\n",
    "        with open(filepath, \"r\",encoding=\"utf-8\")as f:\n",
    "            texte_encode=f.read()\n",
    "        body.text=texte_encode\n",
    "        #Remplissage auto de l'xml:id\n",
    "        root.set('xml:id',id_moreau+\"_\"+source_doc)\n",
    "        tree = ET.ElementTree(root)\n",
    "        #Export du XML complet et pré-rempli\n",
    "        tree.write(\"sortie_xml/%s_%s.xml\" %(id_moreau,source_doc), encoding=\"utf-8\",xml_declaration=False)\n",
    "        #Correction des erreurs générées pendant la fusion txt + xml\n",
    "        with open(\"sortie_xml/%s_%s.xml\" %(id_moreau,source_doc), 'r', encoding=\"utf-8\") as f:\n",
    "            xmlstring=f.read()\n",
    "        xmlstring_corrig = re.sub(\"&lt;\", \"<\",xmlstring)\n",
    "        xmlstring_corrig = re.sub(\"&gt;\", \">\",xmlstring_corrig)\n",
    "        xmlstring_corrig = re.sub(\"&#10;\", \"\",xmlstring_corrig)\n",
    "        xmlstring_corrig = re.sub(\"^\",\"<?xml version='1.0' encoding='UTF-8'?><?xml-model href='https://raw.githubusercontent.com/Antonomaz/ODD/master/Schema/ODD_Antonomaz.rng' type='application/xml' schematypens='http://relaxng.org/ns/structure/1.0'?> <?xml-model href='https://raw.githubusercontent.com/Antonomaz/ODD/master/Schema/ODD_Antonomaz.rng' type='application/xml' schematypens='http://purl.oclc.org/dsdl/schematron'?>\",xmlstring_corrig)\n",
    "        #Ecriture du fichier finalisé\n",
    "        with open(\"sortie_xml/%s_%s.xml\" %(id_moreau,source_doc), \"w\",encoding=\"utf-8\")as f:\n",
    "            fichier_final=f.write(xmlstring_corrig)\n",
    "        print(\"Transformation TXT>XML-TEI terminée.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemple d'utilisation :\n",
    "* Pour générer les XML, déposer ce script au même niveau que les fichiers .txt concaténés et pré-encodés (ex format nom : Moreau85_GALL.txt)\n",
    "* Personnaliser les paramètres de la fonction XML_Generate() ci-dessous (la documentation pour savoir comment remplir les paramètres se trouve dans la cellule ci-dessus, en description de la fonction).\n",
    "* Cliquer sur Cell > Run All.\n",
    "* Si aucun message d'erreur n'apparait, les fichiers XML se trouvent dans le dossier \"sortie_xml\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moreau2273\n",
      "Remplissage auto des métadonnées à partir du tableur ListeMaz: OK.\n",
      "Remplissage auto des métadonnées à partir du tableur Avancee_corpus : OK.\n",
      "Transformation TXT>XML-TEI terminée.\n",
      "Moreau2412\n",
      "Remplissage auto des métadonnées à partir du tableur ListeMaz: OK.\n",
      "Remplissage auto des métadonnées à partir du tableur Avancee_corpus : OK.\n",
      "Transformation TXT>XML-TEI terminée.\n",
      "Moreau3004\n",
      "Remplissage auto des métadonnées à partir du tableur ListeMaz: OK.\n",
      "Remplissage auto des métadonnées à partir du tableur Avancee_corpus : OK.\n",
      "Transformation TXT>XML-TEI terminée.\n"
     ]
    }
   ],
   "source": [
    "XML_generate(fichier_corpus=\"non_classé\",genre=\"non renseigné\",date_creation_fichier=\"3 juin 2021\",\n",
    "                 when_creation_fichier=\"2021-06-03\",name_respXML=\"Roblin Camille\",status_respXML=\"Stagiaire\",\n",
    "                 path_avancee_corpus=\"Avancée_travail_corpus - Corpus_complet.tsv\",\n",
    "             path_ListeMaz=\"ListeMazarinades - Documents_all.tsv\", source_doc=\"GALL\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
